{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "This project is to explore, segment, and cluster the neighborhoods in the city of Toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## I have used all three question in the single notebook\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np # library to handle data in a vectorized manner\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport json # library to handle JSON files\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets.samples_generator import make_blobs\n#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\nfrom bs4 import BeautifulSoup\nimport lxml\nprint('Libraries imported.')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "r = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M')\nsoup = BeautifulSoup(r.text, 'html.parser')\ntable=soup.find('table', attrs={'class':'wikitable sortable'})\n\n#get headers:\nheaders=table.find_all('th')\nfor i, head in enumerate(headers): headers[i]=str(headers[i]).replace(\"<th>\",\"\").replace(\"</th>\",\"\").replace(\"\\n\",\"\")\n\n#Find all items and skip first one:\nrows=table.find_all('tr')\nrows=rows[1:len(rows)]\n\n# skip all meta symbols and line feeds between rows:\nfor i, row in enumerate(rows): rows[i] = str(rows[i]).replace(\"\\n</td></tr>\",\"\").replace(\"<tr>\\n<td>\",\"\")\n\n# make dataframe, expand rows and drop the old one:\ndf=pd.DataFrame(rows)\ndf[headers] = df[0].str.split(\"</td>\\n<td>\", n = 2, expand = True) \ndf.drop(columns=[0],inplace=True)\n\n# skip not assigned boroughs:\ndf = df.drop(df[(df.Borough == \"Not assigned\")].index)\n# give \"Not assigned\" Neighborhoods same name as Borough:\ndf.Neighbourhood.replace(\"Not assigned\", df.Borough, inplace=True)\n\n# copy Borough value to Neighborhood if NaN:\ndf.Neighbourhood.fillna(df.Borough, inplace=True)\n# drop duplicate rows:\ndf=df.drop_duplicates()\n\n# extract titles from columns\ndf.update(\n    df.Neighbourhood.loc[\n        lambda x: x.str.contains('title')\n    ].str.extract('title=\\\"([^\\\"]*)',expand=False))\n\ndf.update(\n    df.Borough.loc[\n        lambda x: x.str.contains('title')\n    ].str.extract('title=\\\"([^\\\"]*)',expand=False))\n\n# delete Toronto annotation from Neighbourhood:\ndf.update(\n    df.Neighbourhood.loc[\n        lambda x: x.str.contains('Toronto')\n    ].str.replace(\", Toronto\",\"\"))\ndf.update(\n    df.Neighbourhood.loc[\n        lambda x: x.str.contains('Toronto')\n    ].str.replace(\"\\(Toronto\\)\",\"\"))\n\n# combine multiple neighborhoods with the same post code\ndf2 = pd.DataFrame({'Postcode':df.Postcode.unique()})\ndf2['Borough']=pd.DataFrame(list(set(df['Borough'].loc[df['Postcode'] == x['Postcode']])) for i, x in df2.iterrows())\ndf2['Neighborhood']=pd.Series(list(set(df['Neighbourhood'].loc[df['Postcode'] == x['Postcode']])) for i, x in df2.iterrows())\ndf2['Neighborhood']=df2['Neighborhood'].apply(lambda x: ', '.join(x))\ndf2.dtypes\n\ndf2.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}